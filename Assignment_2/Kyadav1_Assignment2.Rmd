---
title: "Kyadav1_Assignment2"
author: "Khushboo Yadav"
date: "10/4/2020"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

# 1.Importing libraries & data from csv file

```{r}
library('lattice')
library('ggplot2')
library('FNN') 
library('caret') 
library('e1071') 
library('ISLR') 
library('dplyr') 
library('fastDummies') 
library('gmodels') 

UniversalBank <- read.csv("~/Downloads/UniversalBank.csv")
summary(UniversalBank)
str(UniversalBank)
```
# 2.Dropping ID and zipcode columns
```{r}
UniversalBank<-UniversalBank[,c(-1,-5)] 
summary(UniversalBank)
head(UniversalBank)
```


# 3.Identifying Numerical variable and categorical variable

All the variables in the dataset are of Integer/Num data types Numerical Data:-                  
Age , Experience,Family ,Income,CCAvg,Mortgage

 Categorical Variables :-                                                        
 1.Education, 
 2.Personal Loan , Securities Account , CD account , Online and CreditCard 
 are in Binary format hence not required to be converted to dummy variable

```{r}
UniversalBank_Numerical<-UniversalBank[c(1:3,5,7)]
UniversalBank_Categorical<-UniversalBank[,-c(1:3,5,7)]
head(UniversalBank_Categorical)
```
# 4.Data Transformation
  Steps followed:-
 1.Dummy Variables creation for Education (Level=1,2,3)                         
 2.After creating dummy variables , removed the extra education column          
 3.factor conversion of Personal Loan                                           

```{r}
UniversalBank<-dummy_cols(UniversalBank,select_columns='Education')
UniversalBank<-UniversalBank[,-6] 
UniversalBank[,'Personal.Loan'] <- as.factor(UniversalBank[,'Personal.Loan'])


summary(UniversalBank)
```
# 5.Splitting of data (60%,40%)

```{r}
set.seed(15)

Train1_Index_UniBank = createDataPartition(UniversalBank$Personal.Loan,p=0.60, list=FALSE) 
Train1_Data_UniBank = UniversalBank[Train1_Index_UniBank,]
Validation_Data1_UniBank = UniversalBank[-Train1_Index_UniBank,] 
summary(Train1_Index_UniBank)

summary(Train1_Data_UniBank)
summary(Validation_Data1_UniBank)
nrow(Train1_Data_UniBank)
nrow(Validation_Data1_UniBank)
```
# 6.New Customer dataframe creation

```{r}
New_Customer<-data.frame(
'Age' = 40, 
'Experience' = 10,
'Income' = 84,
'Family' = 2, 
'CCAvg' = 2,
'Mortgage' = 0, 
'personal.loan'<-factor(c(0,1)),
'Securities.Account' = 0, 
'CD.Account' = 0,
'Online' = 1,
'CreditCard' = 1,
'Education_1' = 0,
'Education_2' = 1,
'Education_3' = 0
 )

summary(New_Customer)
str(New_Customer)

```
# 7.Normalization of the data
    Normalization of Training and Validation data                               
    Normalization of New Customer data                                          
```{r}
# Copy the original data
train_norm_df <- Train1_Data_UniBank
valid_norm_df <- Validation_Data1_UniBank
Nw_Cust_Norm_df<-New_Customer

# use preProcess() from the caret package to normalize 
norm_values <- preProcess(Train1_Data_UniBank, method=c("center", "scale"))

train_norm_df <- predict(norm_values, Train1_Data_UniBank) 
valid_norm_df <- predict(norm_values, Validation_Data1_UniBank) 
Nw_Cust_Norm_df<-predict(norm_values, Nw_Cust_Norm_df) 
summary(train_norm_df)
var(train_norm_df)
summary(valid_norm_df)
var(valid_norm_df)
class(train_norm_df)
summary(Nw_Cust_Norm_df)
```
# 8.New Customer classification when k=1
```{r}
knn_pred_cust <- knn(train_norm_df[,c(1:6,8:14)], Nw_Cust_Norm_df[,-7], 
                  cl = train_norm_df[,7], k = 1)
print(knn_pred_cust)                  
```
# Conclusion : The new customer will not be considered for Personal Loan when k=1

# 7.Performing knn clasification with all predictors

 1. performed knn clasification within the range of 1 to 14                     
 2. plotted graph to better understand the result                               
                         

```{r}

set.seed(120)

accuracy_knn <- data.frame(k = seq(1, 14, 1), accuracy = rep(0, 14))

# compute knn for different k on validation.
for(i in 1:14) {
  knn_pred <- knn(train_norm_df[,c(1:6,8:14)], valid_norm_df[,c(1:6,8:14)], 
                  cl = train_norm_df[,7], k = i)
  accuracy_knn[i, 2] <- confusionMatrix(knn_pred,valid_norm_df[,7])$overall[1] 
}

accuracy_knn
plot(accuracy_knn,type='o')

```


# 8.Best K value selection

With the help of graph and the table data , PFB the points I have considered to 
analyze values for k and choose the best k=5.

 1. Higher the value of  accuracy is essential part of choosing best k
 2. Small value of k will give more noise.
 3. Odd value of k also helps in minimizing the noise
 4. The graph goes down after K=5
The best choice of k which balances between overfitting is k=5.

# 9.Confusion Matrix for validation set using best K (k=5)

```{r}
knn_predv5 <- knn(train_norm_df[,c(1:6,8:14)], valid_norm_df[,c(1:6,8:14)], 
                  cl = train_norm_df[,7], k = 5)
confusionMatrix(knn_predv5,valid_norm_df[,7],dnn=c("Actual","Prediction"))
```

# 10.Error Types

There are 2 types of error :-
1.False Positive: Type I Error                                                  
2.False negative: Type II Error                                                 
The confusion matrix has correctly predicted 1799 bank customer who does not    
take the loan and 122 bank customer who will take the personal loan.            
However, it is observed that Type I Error is '9' and                            
Type II Error is '70'.
It means that confusion matrix falsely predicted 9 customers accepting the 
personal loan  and falsely predicted 70 customers to not accepted the Personal loan.


# 11.Merging the Train set and Validation set 

Merging the Train and Validation dataset to perform KNN classification with 
new customer dataset

```{r}
UniversalBank_combined<-rbind.data.frame(train_norm_df,valid_norm_df)
nrow(UniversalBank_combined)
summary(UniversalBank_combined)
```


# 12.Data Re- normalization

To perform KNN classification The combined data(Train+Validation) and 
New customer data set will be normalized

```{r}

Train_UniversalBank_combined_norm_df <- UniversalBank_combined
Test_New_Customer_norm_df <- New_Customer

norm2_values <- preProcess(UniversalBank_combined, method=c("center", "scale"))

Train_UniversalBank_combined_norm_df <- predict(norm2_values, UniversalBank_combined) 
Test_New_Customer_norm_df <- predict(norm2_values, New_Customer) 

summary(Train_UniversalBank_combined_norm_df)
summary(Test_New_Customer_norm_df)


```

# 13.performing KNN classification for new Customer to Predict Personal Loan Acceptance Based on the combined data set(Train+Validation)
```{r}
knn_pred_cust <- knn(train_norm_df[,c(1:6,8:14)], Nw_Cust_Norm_df[,-7], 
                  cl = train_norm_df[,7], k = 5)
print(knn_pred_cust)                  
```
for K=5
```{r}

knn_prediction_5 <- knn(Train_UniversalBank_combined_norm_df[,-7], Test_New_Customer_norm_df[,-7], 
                cl = Train_UniversalBank_combined_norm_df[,7], k = 5)
print(knn_prediction_5)
            
```

# Prediction for New Customer with K=5
In the first part , I have applied K=5 with new Customer Data and used Train data and results is '0' level
                                                                                                    
However, In the second part I have applied K=5 and used combined normalized data(Trainset +Validation set) the results came'1' which means loan acceptance.
Ideally, we should  merge the data and normalize it with new customer data  to get the result.(which is done in the second part)
Based on the results  
We can predict that new customer will accept personal loan . 


# 14.Re-partitioned the data(50%:30%:20%)

Train data , Validation data , Test data , Traval(Train+Validation)

```{r}

set.seed(156)

Test3_Index_UniBank = createDataPartition(UniversalBank$Personal.Loan,p=0.20, list=FALSE) #test data
Test3_Data_UniBank = UniversalBank[Test3_Index_UniBank,]
Traval_Data_UniBank = UniversalBank[-Test3_Index_UniBank,] #left 80 prcnt of data
Train3_Index_UniBank = createDataPartition(Traval_Data_UniBank$Personal.Loan,p=0.625, list=FALSE) #50prcnt of the 80 prcnt data
Train3_Data_UniBank = Traval_Data_UniBank[Train3_Index_UniBank,]
#left 30 prcnt data
Validation3_Data_UniBank=Traval_Data_UniBank[-Train3_Index_UniBank,]

nrow(Train3_Data_UniBank)
nrow(Validation3_Data_UniBank)
nrow(Test3_Data_UniBank)
nrow(Traval_Data_UniBank)
```

# 15. Normalization of the Repartitioned data

```{r}
train3_norm_df <- Train3_Data_UniBank
valid3_norm_df <- Validation3_Data_UniBank
test3_norm_df<-Test3_Data_UniBank
traval_norm_df<-Traval_Data_UniBank

norm_values3 <- preProcess(Train3_Data_UniBank, method=c("center", "scale"))

train3_norm_df <- predict(norm_values3, Train3_Data_UniBank) 
valid3_norm_df <- predict(norm_values3, Validation3_Data_UniBank) 
test3_norm_df<- predict(norm_values3,Test3_Data_UniBank)
traval_norm_df<- predict(norm_values3,Traval_Data_UniBank)
summary(train3_norm_df)
summary(valid3_norm_df)
summary(test3_norm_df)

```

# 16.confusion matrix for  the validation data set 30% and traning dataset 50%

```{r}

knn_Train_Val <- knn(train3_norm_df[,-7], valid3_norm_df[,-7], 
                  cl = train3_norm_df[, 7], k = 5)
confusionMatrix(knn_Train_Val, valid3_norm_df[, 7])
```

# 17.Confusion Matrix for the test dataset with Train data set

```{r}

knn_Train_Test <- knn(train3_norm_df[,-7], test3_norm_df[,-7], 
                  cl = train3_norm_df[, 7], k = 5)
confusionMatrix(knn_Train_Test, test3_norm_df[, 7])
```

# 18.Confusion Matrix for  test dataset with the validation dataset

```{r}
knn_Val_Test <- knn(valid3_norm_df[,-7], test3_norm_df[,-7], 
                  cl = valid3_norm_df[, 7], k = 5)
confusionMatrix(knn_Val_Test, test3_norm_df[, 7])

```

# 19.Confusion matrix for Testing with Traval data (Train+Validation)

```{r}
knn_TraVal_Test <- knn(traval_norm_df[,-7], test3_norm_df[,-7], 
                  cl = traval_norm_df[, 7], k = 5)
confusionMatrix(knn_TraVal_Test, test3_norm_df[, 7])

```
Conclusion :-
From the confusion matrices I can  compute the sensitivity, specificity, accuracy, precision, other performance metrics for each of the classifiers. Accuracy is one most important performance metrics.

a.Confusion Matrix for Test with Training :-     Accuracy:0.956,Sensitivity:0.9967,Specificity:0.5729,Kappa:0.692       
b.Confusion Matrix for Test with Validation:-    Accuracy:0.95,Sensitivity:0.9900,Specificity:0.5729,Kappa:0.6615      
c.Confusion Matrix for Test with Traval :-       Accuracy:0.961,Sensitivity:0.9945,Specificity:0.6458,Kappa:0.7402 
d.Confusion Matrix for Validation with Training:-Accuracy:0.954,Sensitivity:0.9985,Specificity:0.5347,Kappa:0.668

Based on the Accuracy,sensitivity,specificity and Kappa values comparison between 'a' and 'b', confusion matrix for Test with Training seems to be better than Confusion matrix test with Validation .

However,  the confusion matrix Test with Traval(c) performs the best among all other.
By adding train set and validation together leads to  using all the available data  and improving the performance .
